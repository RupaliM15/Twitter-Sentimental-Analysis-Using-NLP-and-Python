{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fdae1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780edcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised â€œminimum government maxim...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "0       when modi promised â€œminimum government maxim...      -1.0\n",
       "1       talk all the nonsense and continue all the dra...       0.0\n",
       "2       what did just say vote for modi  welcome bjp t...       1.0\n",
       "3       asking his supporters prefix chowkidar their n...       1.0\n",
       "4       answer who among these the most powerful world...       1.0\n",
       "...                                                   ...       ...\n",
       "162975  why these 456 crores paid neerav modi not reco...      -1.0\n",
       "162976  dear rss terrorist payal gawar what about modi...      -1.0\n",
       "162977  did you cover her interaction forum where she ...       0.0\n",
       "162978  there big project came into india modi dream p...       0.0\n",
       "162979  have you ever listen about like gurukul where ...       1.0\n",
       "\n",
       "[162980 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the Data from the Given excel file.\n",
    "\n",
    "data=pd.read_excel(r'twitter_data.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064e2f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change our dependent variable to categorical\n",
    "\n",
    "data['category'] = data['category'].map({0: \"Neutral\", -1: \"Negative\", 1: \"Positive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9689f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Missing value analysis and drop all null/missing values\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff750558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    0\n",
       "category      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d9a48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of numerical features : \n",
      "         clean_text  category\n",
      "count       162969    162969\n",
      "unique      162968         3\n",
      "top           2019  Positive\n",
      "freq             2     72249\n",
      "\n",
      "Total number of reviews:  162969\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary statistics of numerical features : \\n\", data.describe())\n",
    "\n",
    "print(\"\\nTotal number of reviews: \",len(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5181399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do Text cleaning\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text) # remove punctuation\n",
    "    text = text.lower() # transform to lowercase\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word not in stop_words] # remove stopwords\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7197e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['clean_text'].apply(lambda x: clean_text(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57f6d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into dependent(X) and independent(y) dataframe\n",
    "\n",
    "X = data['clean_text']\n",
    "y = data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f97b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Operations on Text Data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bae78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and Train an LSTM model\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "input_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "319c8b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=input_length))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "788c08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dummy variable creation for the dependent variable\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y = pd.get_dummies(y).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6555cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f6a2aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4075/4075 [==============================] - 851s 207ms/step - loss: 0.3645 - accuracy: 0.8757\n",
      "Epoch 2/10\n",
      "4075/4075 [==============================] - 842s 207ms/step - loss: 0.2155 - accuracy: 0.9328\n",
      "Epoch 3/10\n",
      "4075/4075 [==============================] - 1045s 257ms/step - loss: 0.1417 - accuracy: 0.9554\n",
      "Epoch 4/10\n",
      "4075/4075 [==============================] - 813s 199ms/step - loss: 0.0922 - accuracy: 0.9701\n",
      "Epoch 5/10\n",
      "4075/4075 [==============================] - 771s 189ms/step - loss: 0.0606 - accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "4075/4075 [==============================] - 680s 167ms/step - loss: 0.0414 - accuracy: 0.9864\n",
      "Epoch 7/10\n",
      "4075/4075 [==============================] - 677s 166ms/step - loss: 0.0294 - accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "4075/4075 [==============================] - 676s 166ms/step - loss: 0.0221 - accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "4075/4075 [==============================] - 2836s 696ms/step - loss: 0.0167 - accuracy: 0.9947\n",
      "Epoch 10/10\n",
      "4075/4075 [==============================] - 682s 167ms/step - loss: 0.0130 - accuracy: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x242a7cebfa0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the new model\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67b628da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019/1019 [==============================] - 9s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the prediction as same as the original data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9826438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      7152\n",
      "           1       0.92      0.87      0.90     11067\n",
      "           2       0.88      0.89      0.89     14375\n",
      "\n",
      "    accuracy                           0.87     32594\n",
      "   macro avg       0.86      0.86      0.86     32594\n",
      "weighted avg       0.87      0.87      0.87     32594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Measure Performance Metrices and Accuracy\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159286b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
